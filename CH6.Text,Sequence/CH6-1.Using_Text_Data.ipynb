{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization\n",
    "- 텍스트 원본을 그대로 사용하여 모델링할 수 없으므로, 텍스트를 수치형 텐서로 변환하는 과정\n",
    "- 어떤 종류의 토큰화를 적용하고, 생성된 토큰에 수치형 벡터를 연결\n",
    "    - token : 텍스트를 나누는 단위(단어, 문자, n-gram)\n",
    "    - tokenization : 나누는 작업\n",
    "\n",
    "# Token - Vector 연결하는 방법\n",
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:46.466195Z",
     "start_time": "2019-05-19T07:42:46.315563Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:47.291461Z",
     "start_time": "2019-05-19T07:42:47.287471Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "token_index = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 수준의 one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:48.053773Z",
     "start_time": "2019-05-19T07:42:48.038814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'cat', 'sat', 'on', 'the', 'mat.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:48.364603Z",
     "start_time": "2019-05-19T07:42:48.358622Z"
    }
   },
   "outputs": [],
   "source": [
    "for sample in samples :\n",
    "    for word in sample.split() :\n",
    "        if word not in token_index :\n",
    "            token_index[word] = len(token_index) +1 #1번부터 단어마다 고유 인덱스 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:48.702255Z",
     "start_time": "2019-05-19T07:42:48.695308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'the': 5,\n",
       " 'mat.': 6,\n",
       " 'dog': 7,\n",
       " 'ate': 8,\n",
       " 'my': 9,\n",
       " 'homework.': 10}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:49.014674Z",
     "start_time": "2019-05-19T07:42:49.006695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 10\n",
    "results = np.zeros(shape = (len(samples), max_length, max(token_index.values())+1))\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:49.456491Z",
     "start_time": "2019-05-19T07:42:49.448510Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, sample in enumerate(samples) :\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length] :\n",
    "        index = token_index.get(word)\n",
    "        results[i,j,index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:49.728204Z",
     "start_time": "2019-05-19T07:42:49.718236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자 수준의 one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:50.580710Z",
     "start_time": "2019-05-19T07:42:50.575720Z"
    }
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:51.169896Z",
     "start_time": "2019-05-19T07:42:51.165908Z"
    }
   },
   "outputs": [],
   "source": [
    "characters = string.printable #출력 가능한 모든 아스키 문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:51.607309Z",
     "start_time": "2019-05-19T07:42:51.599325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10,\n",
       " 'a': 11,\n",
       " 'b': 12,\n",
       " 'c': 13,\n",
       " 'd': 14,\n",
       " 'e': 15,\n",
       " 'f': 16,\n",
       " 'g': 17,\n",
       " 'h': 18,\n",
       " 'i': 19,\n",
       " 'j': 20,\n",
       " 'k': 21,\n",
       " 'l': 22,\n",
       " 'm': 23,\n",
       " 'n': 24,\n",
       " 'o': 25,\n",
       " 'p': 26,\n",
       " 'q': 27,\n",
       " 'r': 28,\n",
       " 's': 29,\n",
       " 't': 30,\n",
       " 'u': 31,\n",
       " 'v': 32,\n",
       " 'w': 33,\n",
       " 'x': 34,\n",
       " 'y': 35,\n",
       " 'z': 36,\n",
       " 'A': 37,\n",
       " 'B': 38,\n",
       " 'C': 39,\n",
       " 'D': 40,\n",
       " 'E': 41,\n",
       " 'F': 42,\n",
       " 'G': 43,\n",
       " 'H': 44,\n",
       " 'I': 45,\n",
       " 'J': 46,\n",
       " 'K': 47,\n",
       " 'L': 48,\n",
       " 'M': 49,\n",
       " 'N': 50,\n",
       " 'O': 51,\n",
       " 'P': 52,\n",
       " 'Q': 53,\n",
       " 'R': 54,\n",
       " 'S': 55,\n",
       " 'T': 56,\n",
       " 'U': 57,\n",
       " 'V': 58,\n",
       " 'W': 59,\n",
       " 'X': 60,\n",
       " 'Y': 61,\n",
       " 'Z': 62,\n",
       " '!': 63,\n",
       " '\"': 64,\n",
       " '#': 65,\n",
       " '$': 66,\n",
       " '%': 67,\n",
       " '&': 68,\n",
       " \"'\": 69,\n",
       " '(': 70,\n",
       " ')': 71,\n",
       " '*': 72,\n",
       " '+': 73,\n",
       " ',': 74,\n",
       " '-': 75,\n",
       " '.': 76,\n",
       " '/': 77,\n",
       " ':': 78,\n",
       " ';': 79,\n",
       " '<': 80,\n",
       " '=': 81,\n",
       " '>': 82,\n",
       " '?': 83,\n",
       " '@': 84,\n",
       " '[': 85,\n",
       " '\\\\': 86,\n",
       " ']': 87,\n",
       " '^': 88,\n",
       " '_': 89,\n",
       " '`': 90,\n",
       " '{': 91,\n",
       " '|': 92,\n",
       " '}': 93,\n",
       " '~': 94,\n",
       " ' ': 95,\n",
       " '\\t': 96,\n",
       " '\\n': 97,\n",
       " '\\r': 98,\n",
       " '\\x0b': 99,\n",
       " '\\x0c': 100}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index = dict(zip(characters, range(1, len(characters)+1)))\n",
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:42:52.821737Z",
     "start_time": "2019-05-19T07:42:52.815751Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values())+1))\n",
    "\n",
    "for i, sample in enumerate(samples) :\n",
    "    for j, character in enumerate(sample) :\n",
    "        index = token_index.get(character)\n",
    "        results[i,j,index]= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras Toeknizer\n",
    "- 특수 문자를 제거하거나, 빈도가 높은 N개의 단어 선택"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
