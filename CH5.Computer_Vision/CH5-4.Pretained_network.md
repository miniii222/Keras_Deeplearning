# Pretained Network

- 사전 훈련된 네트워크
- 원본 데이터셋이 충분히 크고 일반적이라면, 사전 훈련된 네트워크에 의해 학습된 특성의 계층 구조는 실제 세상에 대한 일반적인 모델로 효율적인 역할을 할 수 있다.
- 학습된 특성을 다른 문제에 적용할 수 있는 이런 유연성은 딥러닝의 핵심 장점!

## Feature Extraction (특성 추출)
- 사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아내는 것
- 새로운 분류기를 처음부터 훈련
- 사전에 훈련된 네트워크의 합성곱 기반 층을 선택하여 새로운 데이터를 통과시키고, 그 출력으로 새로운 분류기를 훈련

![image](https://i0.wp.com/tensorflow.rstudio.com/blog/images/keras-pretrained-convnet/swapping_fc_classifier.png?w=456&ssl=1)

#### 왜 합성곱 층만 재사용할까?
- 합성곱 층에 의해 학습된 표현이 더 일반적!
- Classifier(분류기)에 학습한 표현은 모델이 훈련된 클래스 집합에 특화
- 합성곱 층은 객체 위치를 고려(상위 층 - 추상적인 개념 -> 하위 층 - 지역적, 일반적인 개념)

#### ImageNet 데이터로 훈련된 이미지 분류 모델
(keras.applications)

- VGG16
- Xception
- Inception V3
- ResNet50
- VGG19
- MobileNet


## Fine Tuning (미세 조정)
